{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from models.transformer import create_vit_model, fit_vit_model\n",
    "from models.utils.get_train_data import get_average_green_band_data\n",
    "from models.utils.root_mean_squared_error import root_mean_squared_error\n",
    "import os.path as osp\n",
    "import csv\n",
    "import data\n",
    "import matplotlib.pyplot as plt\n",
    "import models\n",
    "import argparse\n",
    "from models.segmenter import prepare_dataset\n",
    "from models.utils.get_train_data import get_all_from_band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "with open(osp.join(osp.dirname(data.__file__), 'patch_names'), newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    patch_name_data = list(reader)\n",
    "patch_names = patch_name_data[0]\n",
    "# patch_names = patch_names[0:100]\n",
    "train_data_path = osp.join(osp.dirname(data.__file__), \"forest-biomass\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# patch_names = patch_names[0:100]\n",
    "\n",
    "band_stds = []\n",
    "band_means = []\n",
    "for band in range(11):\n",
    "\n",
    "    x = get_all_from_band(patch_names, band, train_data_path)\n",
    "    print(x.shape)\n",
    "    band_stds.append(np.std(x))\n",
    "    band_stds.append(np.mean(x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "sentinel_1_bands = {\n",
    "    \"VV ascending\": 0,\n",
    "    \"VH ascending\": 0,\n",
    "    \"VV descending\": 0,\n",
    "    \"VH descending\": 0\n",
    "}\n",
    "\n",
    "sentinel_2_bands = {\n",
    "    \"B2-Blue\": 1,\n",
    "    \"B3-Green\": 1,\n",
    "    \"B4-Red\": 1,\n",
    "    \"B5-Veg red edge 1\": 1,\n",
    "    \"B6-Veg red edge 2\": 1,\n",
    "    \"B7-Veg red edge 3\": 1,\n",
    "    \"B8-NIR\": 1,\n",
    "    \"B8A-Narrow NIR\": 1,\n",
    "    \"B11-SWIR 1\": 1,\n",
    "    \"B12-SWIR 2\": 1,\n",
    "    \"Cloud probability\": 0\n",
    "}\n",
    "\n",
    "s1_list = list(sentinel_1_bands.values())\n",
    "s2_list = list(sentinel_2_bands.values())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "data_path = osp.dirname(data.__file__)\n",
    "\n",
    "training_ids_path = osp.join(data_path, \"patch_names\")\n",
    "training_features_path = osp.join(data_path, \"forest-biomass\")\n",
    "\n",
    "train_dataset, number_of_channels = prepare_dataset(training_ids_path, training_features_path, s1_list, s2_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_mean_and_std(dataloader):\n",
    "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "\n",
    "    for data, _ in tqdm(dataloader):\n",
    "        # Mean over batch, height and width, but not over the channels\n",
    "        channels_sum += torch.mean(data, dim=[0,2,3])\n",
    "        channels_squared_sum += torch.mean(data**2, dim=[0,2,3])\n",
    "        num_batches += 1\n",
    "\n",
    "    means = channels_sum / num_batches\n",
    "\n",
    "    # std = sqrt(E[X^2] - (E[X])^2)\n",
    "    stds = (channels_squared_sum / num_batches - means ** 2) ** 0.5\n",
    "\n",
    "    return means, stds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 608/608 [00:15<00:00, 38.42it/s]\n"
     ]
    }
   ],
   "source": [
    "means, stds = get_mean_and_std(train_dataloader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1666.0227, 1649.1184, 1641.2771, 1960.8578, 2520.4958, 2628.6143,\n        2778.9536, 2723.2520, 1025.0494,  697.5798])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([2539.4539, 2355.2258, 2432.2163, 2428.7878, 2243.6016, 2131.9910,\n        2225.4001, 2053.2605,  930.2753,  755.9792])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4859, 256, 256)\n",
      "(4859, 256, 256)\n",
      "(4859, 256, 256)\n",
      "(4859, 256, 256)\n",
      "(4859, 256, 256)\n",
      "(4859, 256, 256)\n",
      "(4859, 256, 256)\n",
      "(4859, 256, 256)\n",
      "(4859, 256, 256)\n",
      "(4859, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "patch_names = patch_names[0:500]\n",
    "\n",
    "band_stds = []\n",
    "band_means = []\n",
    "for band in range(10):\n",
    "\n",
    "    x = get_all_from_band(patch_names, band, train_data_path)\n",
    "    print(x.shape)\n",
    "    band_stds.append(np.std(x))\n",
    "    band_means.append(np.mean(x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "[2540.3397510567966,\n 2356.076757612205,\n 2433.075508463788,\n 2429.6509315323638,\n 2244.3870278230097,\n 2132.702299852526,\n 2226.137935423653,\n 2053.9244507257426,\n 930.5311195966731,\n 756.2597490490978]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "band_stds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "[1667.4965786145876,\n 1650.426576160997,\n 1642.6580560954665,\n 1962.2058812039554,\n 2521.569034423326,\n 2629.538568440571,\n 2779.872157274094,\n 2724.073150317594,\n 1024.9350094949298,\n 697.6740744387228]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "band_means"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Conclusion, normalizing was already being done in create_tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
