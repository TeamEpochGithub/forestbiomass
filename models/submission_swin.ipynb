{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from pytorch_lightning.strategies import DDPStrategy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import segmentation_models_pytorch as smp\n",
    "import os\n",
    "import rasterio\n",
    "from pytorch_lightning import Trainer\n",
    "import pytorch_lightning as pl\n",
    "import warnings\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from tqdm import tqdm\n",
    "from efficientnet_swin import Efficient_Swin\n",
    "import models\n",
    "import data\n",
    "import csv\n",
    "from models.utils import loss_functions\n",
    "import argparse\n",
    "import models.utils.transforms as tf\n",
    "from models.utils.dataloading import SentinelTiffDataloader, SentinelTiffDataloaderSubmission, create_tensor, \\\n",
    "    apply_transforms, SentinelTiffDataloader_all, SentinelTiffDataloader_all_submission\n",
    "import operator\n",
    "import sys\n",
    "from models.utils.warmup_scheduler.scheduler import GradualWarmupScheduler\n",
    "from models.utils.simple_tensor_accumulate import accumulate_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class Sentinel2Model(pl.LightningModule):\n",
    "    def __init__(self, model, epochs, warmup_epochs, learning_rate, weight_decay, loss_function):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.loss_function = loss_function\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = self.loss_function(y_hat, y)\n",
    "        self.log(\"train/loss\", loss)\n",
    "        self.scheduler.step()\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = self.loss_function(y_hat, y)\n",
    "        self.log(\"val/loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate, betas=(0.9, 0.999), eps=1e-8, weight_decay=self.weight_decay)\n",
    "        scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, self.epochs - self.warmup_epochs,\n",
    "                                                                eta_min=1e-6)\n",
    "        self.scheduler = GradualWarmupScheduler(optimizer,\n",
    "                                           multiplier=1, total_epoch=self.warmup_epochs,\n",
    "                                           after_scheduler=scheduler_cosine)\n",
    "        return [optimizer], [self.scheduler]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "def prepare_dataset_training(args):\n",
    "    with open(args.training_ids_path, newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        patch_name_data = list(reader)\n",
    "    chip_ids = patch_name_data[0]\n",
    "\n",
    "    training_features_path = args.tiff_training_features_path\n",
    "\n",
    "    # id_month_list = []\n",
    "    #\n",
    "    # for current_id in chip_ids:\n",
    "    #     for month in range(5, 12):\n",
    "    #\n",
    "    #         if month < 10:\n",
    "    #             month = \"0\" + str(month)\n",
    "    #\n",
    "    #         month_patch_path = osp.join(training_features_path, f\"{current_id}_S2_{month}.tif\")\n",
    "    #         if osp.exists(month_patch_path):\n",
    "    #             id_month_list.append((current_id, month))\n",
    "\n",
    "    corrupted_transform_method, transform_channels = tf.select_transform_method(args.transform_method,\n",
    "                                                                                in_channels=len(\n",
    "                                                                                    args.bands_to_keep))\n",
    "\n",
    "    new_dataset = SentinelTiffDataloader_all(training_features_path,\n",
    "                                         args.tiff_training_labels_path,\n",
    "                                         chip_ids,\n",
    "                                         args.bands_to_keep,\n",
    "                                         corrupted_transform_method)\n",
    "\n",
    "    return new_dataset\n",
    "\n",
    "\n",
    "def prepare_dataset_testing(args):\n",
    "    with open(args.testing_ids_path, newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        patch_name_data = list(reader)\n",
    "    chip_ids = patch_name_data[0]\n",
    "    testing_features_path = args.tiff_testing_features_path\n",
    "\n",
    "    id_month_list = []\n",
    "\n",
    "    for current_id in chip_ids:\n",
    "        for month in range(5, 12):\n",
    "\n",
    "            if month < 10:\n",
    "                month = \"0\" + str(month)\n",
    "\n",
    "            month_patch_path = osp.join(testing_features_path, f\"{current_id}_S2_{month}.tif\")\n",
    "            if osp.exists(month_patch_path):\n",
    "                id_month_list.append((current_id, month))\n",
    "\n",
    "    corrupted_transform_method, transform_channels = tf.select_transform_method(args.transform_method,\n",
    "                                                                                in_channels=len(\n",
    "                                                                                    args.bands_to_keep))\n",
    "\n",
    "    new_dataset = SentinelTiffDataloader_all_submission(testing_features_path,\n",
    "                                                   chip_ids,\n",
    "                                                   args.bands_to_keep,\n",
    "                                                   corrupted_transform_method)\n",
    "    return new_dataset, chip_ids\n",
    "\n",
    "\n",
    "def select_segmenter(encoder_weights, segmenter_name, encoder_name, number_of_channels):\n",
    "    if segmenter_name == \"Unet\":\n",
    "        base_model = smp.Unet(\n",
    "            encoder_name=encoder_name,\n",
    "            in_channels=161,\n",
    "            classes=1,\n",
    "            encoder_weights=encoder_weights\n",
    "        )\n",
    "    else:\n",
    "        base_model = None\n",
    "\n",
    "    assert base_model is not None, \"Segmenter name was not recognized.\"\n",
    "    return base_model\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    print('=' * 30)\n",
    "    for arg in vars(args):\n",
    "        print('--', arg, ':', getattr(args, arg))\n",
    "    print('=' * 30)\n",
    "\n",
    "    print(\"Getting train data...\")\n",
    "\n",
    "    train_dataset = prepare_dataset_training(args)\n",
    "\n",
    "    train_size = int((1 - args.validation_fraction) * len(train_dataset))\n",
    "    valid_size = len(train_dataset) - train_size\n",
    "\n",
    "    train_set, val_set = torch.utils.data.random_split(train_dataset, [train_size, valid_size])\n",
    "\n",
    "    train_dataloader = DataLoader(train_set, batch_size=args.batch_size, shuffle=True,\n",
    "                                  num_workers=args.dataloader_workers)\n",
    "    valid_dataloader = DataLoader(val_set, batch_size=args.batch_size, shuffle=False,\n",
    "                                  num_workers=args.dataloader_workers)\n",
    "\n",
    "    # base_model = select_segmenter(args.encoder_weights, args.segmenter_name, args.encoder_name, len(args.bands_to_keep))\n",
    "    base_model = Efficient_Swin()\n",
    "\n",
    "    model = Sentinel2Model(model=base_model, epochs=args.epochs, warmup_epochs=args.warmup_epochs, learning_rate=args.learning_rate, weight_decay=args.weight_decay, loss_function=args.train_loss_function)\n",
    "\n",
    "    logger = TensorBoardLogger(\"tb_logs\", name=args.model_identifier)\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        save_top_k=args.save_top_k_checkpoints,\n",
    "        monitor=\"val/loss\",\n",
    "        mode=\"min\",\n",
    "    )\n",
    "\n",
    "    # ddp = DDPStrategy(process_group_backend=\"gloo\")\n",
    "    trainer = Trainer(\n",
    "        max_epochs=args.epochs,\n",
    "        logger=[logger],\n",
    "        log_every_n_steps=args.log_step_frequency,\n",
    "        callbacks=[checkpoint_callback],\n",
    "        num_sanity_val_steps=0,\n",
    "        accelerator='gpu',\n",
    "        devices=1,\n",
    "        # num_nodes=4,\n",
    "        # strategy=ddp\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=valid_dataloader)\n",
    "\n",
    "    return model, str(trainer.callback_metrics['val/loss'].item())\n",
    "\n",
    "\n",
    "def load_model(args):\n",
    "    print(\"Getting saved model...\")\n",
    "\n",
    "    assert osp.exists(args.current_model_path) is True, \"requested model does not exist\"\n",
    "    log_folder_path = args.current_model_path\n",
    "\n",
    "    version_dir = list(os.scandir(log_folder_path))[args.model_version]\n",
    "\n",
    "    checkpoint_dir_path = osp.join(log_folder_path, version_dir, \"checkpoints\")\n",
    "    latest_checkpoint_name = list(os.scandir(checkpoint_dir_path))[-1]\n",
    "    latest_checkpoint_path = osp.join(checkpoint_dir_path, latest_checkpoint_name)\n",
    "\n",
    "    base_model = Efficient_Swin()\n",
    "\n",
    "    # This block might be redundant if we can download weights via the python segmentation models library.\n",
    "    # However, it might be that not all weights are available this way.\n",
    "    # If you have downloaded weights (in the .pt format), put them in the pre-trained-weights folder\n",
    "    # and give the file the same name as the encoder you're using.\n",
    "    # If you do that, this block will try and load them for your model.\n",
    "    pre_trained_weights_dir_path = osp.join(osp.dirname(data.__file__), \"pre-trained_weights\")\n",
    "\n",
    "    if osp.exists(osp.join(pre_trained_weights_dir_path, f\"{args.encoder_name}.pt\")):\n",
    "        pre_trained_weights_path = osp.join(pre_trained_weights_dir_path, f\"{args.encoder_name}.pt\")\n",
    "    else:\n",
    "        pre_trained_weights_path = None\n",
    "\n",
    "    if pre_trained_weights_path is not None:\n",
    "        base_model.encoder.load_state_dict(torch.load(pre_trained_weights_path))\n",
    "\n",
    "    ###########################################################\n",
    "\n",
    "    model = Sentinel2Model(model=base_model, epochs=args.epochs, warmup_epochs=args.warmup_epochs, learning_rate=args.learning_rate, weight_decay=args.weight_decay, loss_function=args.train_loss_function)\n",
    "\n",
    "    checkpoint = torch.load(str(latest_checkpoint_path))\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "    print(\"Model loaded\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_submissions(args):\n",
    "\n",
    "    model = load_model(args)\n",
    "\n",
    "    new_dataset, id_month_list = prepare_dataset_testing(args)\n",
    "\n",
    "    trainer = Trainer(accelerator=\"gpu\", devices=1)\n",
    "\n",
    "    dl = DataLoader(new_dataset, num_workers=14)\n",
    "\n",
    "    predictions = trainer.predict(model, dataloaders=dl)\n",
    "    tensor_id_list = [i[0] for i in id_month_list]\n",
    "    print(\"tensoridlist:\" ,len(tensor_id_list))\n",
    "    transformed_predictions = [x.cpu().squeeze().detach().numpy() for x in predictions]\n",
    "    print(\"transformedpred\", len(transformed_predictions))\n",
    "    linked_tensor_list = list(zip(tensor_id_list, transformed_predictions))\n",
    "    print(\"linkedtensorlist\",len(linked_tensor_list))\n",
    "    # linked_tensor_list = sorted(linked_tensor_list, key=operator.itemgetter(0))\n",
    "    # print(\"linkedtensorlist2\",len(linked_tensor_list))\n",
    "    # averaged_tensor_list = list(accumulate_predictions(linked_tensor_list))\n",
    "    # # print(\"avgtensorlist\",len(averaged_tensor_list))\n",
    "    count=0\n",
    "    for id_tensor_pair in linked_tensor_list:\n",
    "        current_id = id_tensor_pair[0]\n",
    "        current_tensor = id_tensor_pair[1]\n",
    "\n",
    "        agbm_path = osp.join(args.submission_folder_path, f\"{current_id}_agbm.tif\")\n",
    "\n",
    "        im = Image.fromarray(current_tensor)\n",
    "        im.save(agbm_path)\n",
    "        count += 1\n",
    "        print(count)\n",
    "\n",
    "    print(\"Finished creating submission.\")\n",
    "\n",
    "\n",
    "def set_args():\n",
    "    data_type = \"tiff\"  # options are \"npy\" or \"tiff\"\n",
    "    epochs = 1500\n",
    "    warmup_epochs = 20\n",
    "    learning_rate = 1e-4\n",
    "    weight_decay = 5e-4\n",
    "    dataloader_workers = 8\n",
    "    validation_fraction = 0.15\n",
    "    batch_size = 16\n",
    "    log_step_frequency = 200\n",
    "    version = -1  # Keep -1 if loading the latest model version.\n",
    "    save_top_k_checkpoints = 3\n",
    "    transform_method = \"replace_corrupted_0s\"  # \"replace_corrupted_noise\"  # nothing  # add_band_corrupted_arrays\n",
    "    train_loss_function = loss_functions.rmse_loss\n",
    "    val_loss_function = loss_functions.rmse_loss\n",
    "\n",
    "    # WARNING: Only increment extra_channels when making predictions/submission (based on the transform method used)\n",
    "    # it is automatically incremented during training based on the transform method used (extra channels generated)\n",
    "    extra_channels = 0\n",
    "\n",
    "    band_map = {\n",
    "        # S2 bands\n",
    "        0: 'S2-B2: Blue-10m',\n",
    "        1: 'S2-B3: Green-10m',\n",
    "        2: 'S2-B4: Red-10m',\n",
    "        3: 'S2-B5: VegRed-704nm-20m',\n",
    "        4: 'S2-B6: VegRed-740nm-20m',\n",
    "        5: 'S2-B7: VegRed-780nm-20m',\n",
    "        6: 'S2-B8: NIR-833nm-10m',\n",
    "        7: 'S2-B8A: NarrowNIR-864nm-20m',\n",
    "        8: 'S2-B11: SWIR-1610nm-20m',\n",
    "        9: 'S2-B12: SWIR-2200nm-20m',\n",
    "        10: 'S2-CLP: CloudProb-160m',\n",
    "        # S1 bands\n",
    "        11: 'S1-VV-Asc: Cband-10m',\n",
    "        12: 'S1-VH-Asc: Cband-10m',\n",
    "        13: 'S1-VV-Desc: Cband-10m',\n",
    "        14: 'S1-VH-Desc: Cband-10m',\n",
    "        # Bands derived by transforms\n",
    "        15: 'S2-NDVI: (NIR-Red)/(NIR+Red) 10m',\n",
    "        16: 'S1-NDVVVH-Asc: Norm Diff VV & VH, 10m',\n",
    "        17: 'S2-NDBI: Difference Built-up Index, 20m',\n",
    "        18: 'S2-NDRE: Red Edge Vegetation Index, 20m',\n",
    "        19: 'S2-NDSI: Snow Index, 20m',\n",
    "        20: 'S2-NDWI: Water Index, 10m',\n",
    "        21: 'S2-SWI: Sandardized Water-Level Index, 20m',\n",
    "        22: 'S1-VV/VH-Asc: Cband-10m',\n",
    "        23: 'S2-VV/VH-Desc: Cband-10m'\n",
    "    }\n",
    "\n",
    "    # bands_to_keep = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
    "    bands_to_keep = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14]\n",
    "    band_indicator = [\"1\" if k in bands_to_keep else \"0\" for k, v in band_map.items()]\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    bands_to_keep_indicator = \"bands-\" + ''.join(str(x) for x in band_indicator)\n",
    "    model_identifier = f\"efficientnet_swin_{bands_to_keep_indicator}\"\n",
    "\n",
    "    parser.add_argument('--model_identifier', default=model_identifier, type=str)\n",
    "    # parser.add_argument('--segmenter_name', default=model_segmenter, type=str)\n",
    "    parser.add_argument('--encoder_name', default=\"efficient_swin\", type=str)\n",
    "    # parser.add_argument('--encoder_weights', default=model_encoder_weights, type=str)\n",
    "    parser.add_argument('--model_version', default=version, type=int)\n",
    "    parser.add_argument('--data_type', default=data_type, type=str)\n",
    "\n",
    "    data_path = osp.dirname(data.__file__)\n",
    "    models_path = osp.dirname(models.__file__)\n",
    "    data_path = r\"C:\\Users\\Team Epoch A\\Documents\\Epoch III\\forestbiomass\\data\"\n",
    "\n",
    "    parser.add_argument('--tiff_training_features_path', default=str(osp.join(data_path, \"imgs\", \"train_features\")))\n",
    "    parser.add_argument('--tiff_training_labels_path', default=str(osp.join(data_path, \"imgs\", \"train_agbm\")))\n",
    "    parser.add_argument('--tiff_testing_features_path', default=str(osp.join(data_path, \"imgs\", \"test_features\")))\n",
    "\n",
    "    parser.add_argument('--training_ids_path', default=str(osp.join(data_path, \"patch_names\")), type=str)\n",
    "    parser.add_argument('--testing_ids_path', default=str(osp.join(data_path, \"test_patch_names\")), type=str)\n",
    "    parser.add_argument('--current_model_path', default=str(osp.join(models_path, \"tb_logs\", model_identifier)),\n",
    "                        type=str)\n",
    "    parser.add_argument('--submission_folder_path', default=str(osp.join(data_path, \"imgs\", \"test_agbm\")), type=str)\n",
    "\n",
    "    parser.add_argument('--dataloader_workers', default=dataloader_workers, type=int)\n",
    "    parser.add_argument('--batch_size', default=batch_size, type=int)\n",
    "    parser.add_argument('--epochs', default=epochs, type=int)\n",
    "    parser.add_argument('--learning_rate', default=learning_rate, type=float)\n",
    "    parser.add_argument('--validation_fraction', default=validation_fraction, type=float)\n",
    "    parser.add_argument('--log_step_frequency', default=log_step_frequency, type=int)\n",
    "    parser.add_argument('--save_top_k_checkpoints', default=save_top_k_checkpoints, type=int)\n",
    "\n",
    "    parser.add_argument('--bands_to_keep', default=bands_to_keep, type=list)\n",
    "    parser.add_argument('--train_loss_function', default=train_loss_function)\n",
    "    parser.add_argument('--val_loss_function', default=val_loss_function)\n",
    "    parser.add_argument('--transform_method', default=transform_method, type=str)\n",
    "    parser.add_argument('--extra_channels', default=extra_channels, type=int)\n",
    "    parser.add_argument('--warmup_epochs', default=warmup_epochs, type=int)\n",
    "    parser.add_argument('--weight_decay', default=weight_decay, type=float)\n",
    "\n",
    "    args = parser.parse_args(\"\")\n",
    "\n",
    "    return args\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting saved model...\n",
      "Model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "model = load_model(set_args())\n",
    "\n",
    "new_dataset, chip_ids = prepare_dataset_testing(set_args())\n",
    "\n",
    "trainer = Trainer(accelerator=\"gpu\", devices=1)\n",
    "\n",
    "dl = DataLoader(new_dataset, num_workers=14)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: C:\\Users\\lvblo\\PycharmProjects\\forestbiomass\\models\\lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/plain": "Predicting: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9ec8576a9c174bdbbb4772677a62286e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lvblo\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x000001A73A56F4C0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lvblo\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"C:\\Users\\lvblo\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1430, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"C:\\Users\\lvblo\\miniconda3\\lib\\multiprocessing\\process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"C:\\Users\\lvblo\\miniconda3\\lib\\multiprocessing\\popen_spawn_win32.py\", line 108, in wait\n",
      "    res = _winapi.WaitForSingleObject(int(self._handle), msecs)\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(model, dataloaders=dl)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transformed_predictions = [x.cpu().squeeze().detach().numpy() for x in predictions]\n",
    "linked_tensor_list = list(zip(chip_ids, transformed_predictions))\n",
    "linked_tensor_list = sorted(linked_tensor_list, key=operator.itemgetter(0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
